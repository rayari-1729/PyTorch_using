{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmpECzXCUZ_a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given $4$ data points $(x_i,y_i)$  and wanted to find a function $f$ such that $f(x_i) = y_i$. Since each $x_i$ was a vector of length $2$, we chose the function\n",
        " $$f(x) = A_1(A_2(x))$$\n",
        "where  $A_1$ is a $8 \\times 2$ matrix and $A_2$ is a $1\\times 8$ matrix. This means there were  $16+8$ free parameters. This simple function did not do a very good job of making $f(x_i) = y_i$."
      ],
      "metadata": {
        "id": "oNoEY6IhVojm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
        "y = torch.tensor([1,5,2,5]).float()\n",
        "\n",
        "class MyNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Matrix1 = nn.Linear(2,8,bias=False)\n",
        "        self.Matrix2 = nn.Linear(8,1,bias=False)\n",
        "    def forward(self,x):\n",
        "        x = self.Matrix1(x)\n",
        "        x = self.Matrix2(x)\n",
        "        return x.squeeze()\n",
        "    \n",
        "f = MyNeuralNet()\n",
        "opt = SGD(f.parameters(), lr=0.001)\n",
        "L = nn.MSELoss()\n",
        "\n",
        "# Train model\n",
        "losses = []\n",
        "for _ in range(50):\n",
        "    opt.zero_grad() # flush previous epoch's gradient\n",
        "    loss_value = L(f(x), y) #compute loss\n",
        "    loss_value.backward() # compute gradient\n",
        "    opt.step() # Perform iteration using gradient above\n",
        "    losses.append(loss_value.item())"
      ],
      "metadata": {
        "id": "_nQt1ZQ_VRVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq0UP5naWxp6",
        "outputId": "4cc42072-9f1c-4eda-e929-6f96ed527118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 5., 2., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHZ-uJY4XYbA",
        "outputId": "bbf2fbbd-9915-4d91-9679-84e6d88420d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.5283, 2.9805, 0.9094, 4.5583], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it turns out, our previous model was not very good at all. In fact, although there were $24$ parameters in the two matrices, there was technically only **two** independent parameters. This is because \n",
        "$$A_2A_1 = B $$ \n",
        "where $B $ is a $2\\times 1 $ matrix. So really our function was $f(x) = Bx $\n",
        "\n",
        "#How can we use this simplicity of linear algebra but have advanced models? \n",
        "\n",
        "The Crux of Machine Learning: This lies in so-called activation functions, which add ever-so-slight non-linearities to a sequence of matrix transformations. Instead of the transformation\n",
        "\n",
        "$$\\text{Old Model :} f(x) = A_2A_1x$$\n",
        "consider instead \n",
        "$$\\text{New Model :}f_2(x) = A_2R(A_1x)$$\n",
        "Where $R$ is an elementwise operator defined by \n",
        "$$R(x) = \\begin{cases} x &x>0 \\\\ 0 & x\\le 0\n",
        "   \\end{cases} $$\n",
        "\n",
        "   So $R$ is an Identity funbction if $x>0$ but set values equal to zero . Thgis is **so-close** to being a linear operator , but it ia not . "
      ],
      "metadata": {
        "id": "fIxcB7ZPXfEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[4,6,2,-1,6,2,5],[1,6,2,-6,5,-3,5]])\n",
        "x"
      ],
      "metadata": {
        "id": "Zyq0M73JXZuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a2c25c-7718-4cc9-d964-5d26ec55a2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  6,  2, -1,  6,  2,  5],\n",
              "        [ 1,  6,  2, -6,  5, -3,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R = nn.ReLU()\n",
        "R(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAYtNDupdC5r",
        "outputId": "e8057d85-71bc-4301-cf7f-8f937f2fc1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 6, 2, 0, 6, 2, 5],\n",
              "        [1, 6, 2, 0, 5, 0, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another example**"
      ],
      "metadata": {
        "id": "KJFtEgU0dI5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.linspace(-3,3,100)\n",
        "y = R(x)"
      ],
      "metadata": {
        "id": "JjK2rGvWdEPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfuHyeO4dL3h",
        "outputId": "888dcd78-cdcd-4089-fcc7-eb51608fe6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0303, 0.0909, 0.1515, 0.2121,\n",
              "        0.2727, 0.3333, 0.3939, 0.4545, 0.5152, 0.5758, 0.6364, 0.6970, 0.7576,\n",
              "        0.8182, 0.8788, 0.9394, 1.0000, 1.0606, 1.1212, 1.1818, 1.2424, 1.3030,\n",
              "        1.3636, 1.4242, 1.4848, 1.5455, 1.6061, 1.6667, 1.7273, 1.7879, 1.8485,\n",
              "        1.9091, 1.9697, 2.0303, 2.0909, 2.1515, 2.2121, 2.2727, 2.3333, 2.3939,\n",
              "        2.4545, 2.5152, 2.5758, 2.6364, 2.6970, 2.7576, 2.8182, 2.8788, 2.9394,\n",
              "        3.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x.numpy(), y.numpy())\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Q8Q14KB5dNFv",
        "outputId": "1ba6fd46-7b7a-4ef1-da80-a7c2e7c68551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now question is **How much better does our model do with this simple adjustment?**"
      ],
      "metadata": {
        "id": "poWD6anpdVbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Matrix1 = nn.Linear(2,8,bias=False)\n",
        "        self.Matrix2 = nn.Linear(8,1,bias=False)\n",
        "        self.R = nn.ReLU()   ## This is the only difference \n",
        "    def forward(self,x):\n",
        "        x = self.R(self.Matrix1(x))\n",
        "        x = self.Matrix2(x)\n",
        "        return x.squeeze()"
      ],
      "metadata": {
        "id": "N7oDyq5EdQvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model (lets write a function to do this, since we'll be doing it a lot)"
      ],
      "metadata": {
        "id": "GJ32yf2Hdlb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(x,y,f, n_epochs=50):\n",
        "    opt = SGD(f.parameters(), lr=0.001) #Optimizer \n",
        "    L = nn.MSELoss()                    # Loss function \n",
        "\n",
        "    # Train model\n",
        "    losses = []\n",
        "    for _ in range(n_epochs):\n",
        "        opt.zero_grad() # flush previous epoch's gradient\n",
        "        loss_value = L(f(x), y) #compute loss\n",
        "        loss_value.backward() # compute gradient\n",
        "        opt.step() # Perform iteration using gradient above\n",
        "        losses.append(loss_value.item())\n",
        "    return f, losses"
      ],
      "metadata": {
        "id": "Yo5KFJIAdako"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
        "y = torch.tensor([1,5,2,5]).float()\n",
        "f2 = MyNeuralNet2()\n",
        "\n",
        "# Train model\n",
        "f2, losses2 = train_model(x,y,f2, n_epochs=5000)"
      ],
      "metadata": {
        "id": "eGWt1EXldnU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-l0bqtedy8w",
        "outputId": "29a9cefa-2b28-4272-f426-8c20a90753f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 5., 2., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPwVPuL4d2RI",
        "outputId": "eec1d597-4ee5-43ad-9979-6ce8c2f064f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.5283, 2.9805, 0.9094, 4.5583], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slightly better. But the real advantage of this slight non-linearity is that we can make our matrices much larger. **Lets make our matrices size $80 \\times 2 $ and  $1 \\times 80 $**. This **only** works because of our non-linearity function $R(x)$:\n",
        "\n",
        "\n",
        " * Without $R(X)$ , we would just have $A_2A_1 = B$ and so $f(x)=Bx$ where $B$ is still a $1\\times 2$ matrix even though $A_2$ and $A_1$ are larger matrices. The non-linearlity function $R(x)$  , to some extent , makes all $240$ parameters more independent from each other .\n",
        "\n",
        " $$\\text{Old Model :} f(x) = A_2R(A_1x) \\, , A_2 \\, is \\, 1\\times 8 \\, and \\, A_1 \\, is \\, 8 \\times 2 \\\\ \\text{New Model:} f_3(x) = A_2R(A_1x)\\, , A_2 \\, is \\, 1\\times 80 \\, and \\, A_1 \\, is \\, 80 \\times 2$$ "
      ],
      "metadata": {
        "id": "wYJFQNJpd9h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNet3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Matrix1 = nn.Linear(2,80, bias=False)\n",
        "        self.Matrix2 = nn.Linear(80,1, bias=False)\n",
        "        self.R = nn.ReLU()\n",
        "    def forward(self,x):\n",
        "        x = self.R(self.Matrix1(x))\n",
        "        x = self.Matrix2(x)\n",
        "        return x.squeeze()"
      ],
      "metadata": {
        "id": "wQBoqkjxd49w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model:"
      ],
      "metadata": {
        "id": "NHe-mP0Rpp6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
        "y = torch.tensor([1,5,2,5]).float()\n",
        "f3 = MyNeuralNet3()\n",
        "\n",
        "# Train model\n",
        "f3, losses3 = train_model(x,y,f3, n_epochs=5000)"
      ],
      "metadata": {
        "id": "1aeiTjrxpoYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smGA2Rdqpr5q",
        "outputId": "7a2692a0-6f45-4cd6-a278-e81e4cb51280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 5., 2., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f3(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxmUZGVfptXJ",
        "outputId": "a506ccf1-ba30-4d63-ed89-aa2205c71981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.8996, 3.7738, 1.9274, 5.1135], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Closer, but still not exact. We can make our model better by introducing other parameters:\n",
        "$$f(x) =A_2R(A_1x+b_1)+b_2$$\n",
        "where $b_1$ and $b_2$ are vectors added to each of the linear transformations.\n",
        "\n",
        " $$\\text{Old Model :} f_3(x) = A_2R(A_1x)\\, , A_2 \\, is \\, 1\\times 80 \\, and \\, A_1 \\, is \\, 80 \\times 2 \\\\ \\text{New Model:} f_4(x) =A_2R(A_1x+b_1)+b_2\\, , A_2 \\, is \\, 1\\times 80 \\, and \\, A_1 \\, is \\, 80 \\times 2$$ "
      ],
      "metadata": {
        "id": "fVg-b32Opx5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNet4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Matrix1 = nn.Linear(2,80)\n",
        "        self.Matrix2 = nn.Linear(80,1)\n",
        "        self.R = nn.ReLU()\n",
        "    def forward(self,x):\n",
        "        x = self.R(self.Matrix1(x))\n",
        "        x = self.Matrix2(x)\n",
        "        return x.squeeze()"
      ],
      "metadata": {
        "id": "yGGNF1AapvXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
        "y = torch.tensor([1,5,2,5]).float()\n",
        "f4 = MyNeuralNet4()\n",
        "\n",
        "# Train model\n",
        "f4, losses4 = train_model(x,y,f4, n_epochs=5000)"
      ],
      "metadata": {
        "id": "1n472QmKql0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXxDCxKqqn6Z",
        "outputId": "829f25c0-4f41-4069-ff77-fa102c1af8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 5., 2., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f4(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3fzR4v4qpJh",
        "outputId": "1e2c7228-edf9-4089-a434-0d323a30435e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5699, 4.2764, 2.0183, 5.0369], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better, but its still not getting us that close to $y$, however. What if we add another matrix in the middle?\n",
        " $$\\text{Old Model :} f_4(x) =A_2R(A_1x+b_1)+b_2\\, , A_2 \\, is \\, 1\\times 80 \\, and \\, A_1 \\, is \\, 80 \\times 2\\\\ \\text{New Model:} f_5 (x) =  A_3R(A_2(A_1X+b_1)+b_2)+b_3 \\, , A_3 \\, is \\, 1\\times 80 \\, and \\, A_2 = 80 \\times 80 \\, and \\, A_1 \\, is \\, 80 \\times 2$$ "
      ],
      "metadata": {
        "id": "hXttoAWJqsjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Matrix1 = nn.Linear(2,80)\n",
        "        self.Matrix2 = nn.Linear(80,80)\n",
        "        self.Matrix3 = nn.Linear(80,1)\n",
        "        self.R = nn.ReLU()\n",
        "    def forward(self,x):\n",
        "        x = self.R(self.Matrix1(x))\n",
        "        x = self.R(self.Matrix2(x))\n",
        "        x = self.Matrix3(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
        "y = torch.tensor([1,5,2,5]).float()\n",
        "f5 = MyNeuralNet5()\n",
        "\n",
        "# Train model\n",
        "f5, losses5 = train_model(x,y,f5, n_epochs=5000)"
      ],
      "metadata": {
        "id": "BlxRu9qzqqaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhxQZ44PrpDL",
        "outputId": "da300e45-d581-485e-cab4-65d824eba6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 5., 2., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f5(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgPxEN4UrqcS",
        "outputId": "4313794a-0617-419b-9d60-a044de4ae3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0003, 4.9997, 2.0000, 5.0001], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its predicting  almost exactly (albeit by overfitting, no doubt, but the message here is that the model has the potential to fit to these arbitrary data points, through a sequence of linear transofmrations followed by slightly non-linear )\n",
        "$\\require{color}$\n",
        "# The \"Sequential\" Neural Network\n",
        "A general \"sequential\" neural network can be expressed as\n",
        "$$\\colorbox{yellow}{$f(x) = \\cal{K}_{i = 1}^nr_i(A_ix+b_i)$}$$\n",
        "\n",
        "where  $\\cal{K}_{i = 1}^nr_i(A_ix+b_i) = f_n \\circ f_{n-1}... \\circ f_1(x) $\n",
        "  and the  are matrices and $A_i$ the $b_i$ are bias vectors. Typically the $R_i$ are the same for all the layers (typically ReLU) **except** for the last layer, where $R_i$ is just is just the identity function\n",
        "\n",
        "  * **Note**: In clever architectures, like convolutional neural networks, the 's become sparse matrices (most of there parameters are fixed to equal zero)."
      ],
      "metadata": {
        "id": "mMxMoRAIrxiw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ECLzfkgYrrrJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}